<!DOCTYPE html>
<!-- CoderPad (c) 2013 Vincent Woo -->
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
<script type="text/javascript">window.NREUM||(NREUM={});NREUM.info={"beacon":"beacon-2.newrelic.com","errorBeacon":"jserror.newrelic.com","licenseKey":"586aeabffa","applicationID":"2434573","transactionName":"cF5XTRNfXF9VQxkSVVdCFkoJX0c=","queueTime":10,"applicationTime":182,"ttGuid":"","agentToken":null,"agent":"js-agent.newrelic.com/nr-314.min.js"}</script>
<script type="text/javascript">window.NREUM||(NREUM={}),__nr_require=function a(b,c,d){function e(f){if(!c[f]){var g=c[f]={exports:{}};b[f][0].call(g.exports,function(a){var c=b[f][1][a];return e(c?c:a)},g,g.exports,a,b,c,d)}return c[f].exports}for(var f=0;f<d.length;f++)e(d[f]);return e}({"4O2Y62":[function(a,b){function c(a,b){var c=d[a];return c?c.apply(this,b):(e[a]||(e[a]=[]),void e[a].push(b))}var d={},e={};b.exports=c,c.queues=e,c.handlers=d},{}],handle:[function(a,b){b.exports=a("4O2Y62")},{}],YLUGVp:[function(a,b){function c(){var a=m.info=NREUM.info;if(a&&a.agent&&a.licenseKey&&a.applicationID){m.proto="https"===l.split(":")[0]||a.sslForHttp?"https://":"http://",g("mark",["onload",f()]);var b=i.createElement("script");b.src=m.proto+a.agent,i.body.appendChild(b)}}function d(){"complete"===i.readyState&&e()}function e(){g("mark",["domContent",f()])}function f(){return(new Date).getTime()}var g=a("handle"),h=window,i=h.document,j="addEventListener",k="attachEvent",l=(""+location).split("?")[0],m=b.exports={offset:f(),origin:l};i[j]?(i[j]("DOMContentLoaded",e,!1),h[j]("load",c,!1)):(i[k]("onreadystatechange",d),h[k]("onload",c)),g("mark",["firstbyte",f()])},{handle:"4O2Y62"}],loader:[function(a,b){b.exports=a("YLUGVp")},{}]},{},["YLUGVp"]);</script>
  <meta name="description"
    content="CoderPad is the best tool available for conducting programming phone screen interviews. Edit code and run it with your candidate, realtime in the browser.">
  <link rel="shortcut icon" href="//d146h09pbg0b1a.cloudfront.net/assets/coderpad_logo_32x32-4cb7162b76ccaa9584b63b603f47e139.png">

  <title>CoderPad - Java</title>

  <link href="//fonts.googleapis.com/css?family=Bitter:400,700|Lato:300,700" media="all" rel="stylesheet" />
  <link href="//d146h09pbg0b1a.cloudfront.net/assets/application-c992391beaa069692384c4b76e08bd1b.css" media="all" rel="stylesheet" />
  
  
</head>
<body class="pad">

  
  

  
<div id="overlay">
  <div>
      <p>
        <span>Welcome to CoderPad!</span><br>
        Identify yourself below, if you please.
      </p>
      <input id="name-prompt">
      <button id="go" class="btn btn-primary">
        Go!
      </button>
  </div>
</div>

<div id="header">

  <div id="header-wrapper">
      <button
        class="btn btn-primary tooltip-target"
        id="run"
        data-toggle="tooltip"
        title="Shortcut: ctrl + enter"
        data-placement="bottom"
        data-html="true"
      >
        Run
        <span class="fui-play"></span>
      </button>


    <a
      id="settings-toggle"
      href="#"
      data-toggle="modal"
      data-target="#settings-modal"
    >
      <span
        class="fui-gear tooltip-target"
        data-toggle="tooltip"
        data-placement="bottom"
        title="Pad settings"
      ></span>
    </a>

  </div>
</div>

<div id="workspace-wrap" class="pad">
  <div id="workspace" class="java">
    <div id="editor" class="pane">
      <span class="pane-label">Java Code</span>
      <div id="editor-widget" class="codemirror-container"></div>
    </div>
    <div id="vertical" class="resizer"></div>
    <div id="right-pane">
        <div id="execution-log" class="pane full">
          <span class="pane-label">Results</span>
        </div>
    </div>
  </div>
</div>

<div id="sidebar">
  <ol id="users"></ol>

  <p>
    CoderPad is a collaborative code editor with real-time execution
     built straight into the browser.
  </p>
    <p><a href="https://plus.google.com/hangouts/_?gid=583721984460&amp;gd=https%3A%2F%2Fcoderpad.io%2F550431">Open Google Hangout</a></p>
  </p>
</div>




<script>
  window.lang     = 'java';
  window.pad      = '550431';
  window.username = null ||
    ('Guest ' + Math.floor(Math.random() * 1000));
  window.snippets = {"Digits":"// To execute Java, please define \"static void main\" on a class\r\n// named Solution.\r\n\r\n/*\r\n\r\nCount the number of digits in an integer\r\n\r\n*/\r\n\r\nclass Solution {\r\n  public static void main(String[] args) {\r\n  }\r\n}\r\n","Duplicate Value":"// To execute Java, please define \"static void main\" on a class\r\n// named Solution.\r\n\r\n/*\r\n\r\nYou have a sorted array with 1,000,001 values from 1-\u003E1M. One of the values is in the array two times. Find this value\r\n\r\n*/\r\n\r\nclass Solution {\r\n  public static void main(String[] args) {\r\n  }\r\n}\r\n","Rate Limiting":"// To execute Java, please define \"static void main\" on a class\r\n// named Solution.\r\n\r\n/*\r\n\r\nImplement rate limiting for an API so that we rate limit if the same developer makes \u003E 10K req/sec. What would the logic be? What would the structure be? Where would you store this structure?\r\n\r\n*/\r\n\r\nclass Solution {\r\n  public static void main(String[] args) {\r\n  }\r\n}\r\n","[Web - JS] Collecting Responses":"// Using Javascript make 5 async calls in a loop and return or call a callback when all responses have come back\r\n\r\n// for example:\r\nvar callback = function() { };\r\nvar users = [1,2,3,4,5];\r\n\r\nfor( i in users ) {\r\n\r\n}","Basic Hadoop Sort":"// To execute Java, please define \"static void main\" on a class\r\n// named Solution.\r\n\r\n/*\r\n\r\nYou are given the task to extract the top N (your solution should be general, but you can work with N=10) pieces of content for users.  \r\nYour input data is in the form\r\n\"{user}\\t{String content}\\t{score}\\n\" where the score is a number from 0.0 to 1.0\r\nPlease write Map/Reduce code to generate the top N results per user.\r\n\r\nFor reference sake, I've provided links to the Mapper class(http://hadoop.apache.org/common/docs/current/api/org/apache/hadoop/mapreduce/Mapper.html), the Reducer Class(http://hadoop.apache.org/common/docs/current/api/org/apache/hadoop/mapreduce/Reducer.html), and the Partitioner class (http://hadoop.apache.org/common/docs/current/api/org/apache/hadoop/mapreduce/Partitioner.html)\r\n\r\n*/\r\n\r\nclass Solution {\r\n  public static void main(String[] args) {\r\n  }\r\n}\r\n","[Web - JS] Linkify a String of Names":"/* Let's say you have string of comma separated names:\r\n\r\nvar s = 'frank, bob, chris';\r\n\r\nHow would you go about transforming that list into the following html?\r\n\r\n\u003Ca href=\"klout.com/frank\u003Efrank\u003C/a\u003E, \u003Ca href=\"klout.com/bob\u003Ebob\u003C/a\u003E, \u003Ca href=\"klout.com/chris\u003Echris\u003C/a\u003E\r\n\r\n*/\r\n  \r\n","Invert a linked list":"// To execute Java, please define \"static void main\" on a class\r\n// named Solution.\r\n\r\n/*\r\n\r\nRepresent a linked list then invert it.\r\n\r\n*/\r\n\r\nclass Solution {\r\n  public static void main(String[] args) {\r\n  }\r\n}\r\n","Permuations":"// To execute Java, please define \"static void main\" on a class\r\n// named Solution.\r\n\r\n/*\r\n\r\nGenerate all permutations of an array of numbers 1..N.\r\n\r\n*/\r\n\r\nclass Solution {\r\n  public static void main(String[] args) {\r\n  }\r\n}\r\n","Anagrams":"// To execute Java, please define \"static void main\" on a class\r\n// named Solution.\r\n\r\n/*\r\n\r\nYou have a few files (couple of GB each) containing words (one word per line).\r\n\r\nI would like to generate output with all words that are anagrams of each other to appear in a single line.\r\n\r\nExample:\r\n\r\nFile-1:      File2:\r\n\r\nnoon         tap\r\nonon         pam\r\nmap\r\npat\r\n\r\nOutput:\r\nnoon onon\r\nmap pam\r\ntap pat\r\n\r\n*/\r\n\r\nclass Solution {\r\n  public static void main(String[] args) {\r\n  }\r\n}\r\n","Token Frequency Counter":"// To execute Java, please define \"static void main\" on a class\r\n// named Solution.\r\n\r\n/*\r\nInput : Stream of tokens with one token per line. Count the frequency of each token in the stream. \r\n\r\nPart A : Assume its a small data set.\r\nPart B : Extend your solution to scale for a big data set.\r\n*/\r\n\r\nclass Solution {\r\n  public static void main(String[] args) {\r\n  }\r\n}\r\n","Grid":"// To execute Java, please define \"static void main\" on a class\r\n// named Solution.\r\n\r\n/*\r\nYou have a nXn grid. The only two ways you can traverse the grid is by going up or by going right. \r\n\r\nFor a 4X4 grid - How many unique paths can you take to reach the end point from the start? Assume the start position is bottom left corner and the end position is top right corner. Write code to solve the problem. \r\n\r\n\r\n   __ __ __ __   End\r\n  |__|__|__|__|\r\n  |__|__|__|__|\r\n  |__|__|__|__|\r\n  |__|__|__|__|\r\n\r\nStart\r\n\r\nExample for 1X1 grid\r\n\r\n\r\n D __ C\r\n  |__|\r\n A   B\r\n\r\nA is start point and C is end point and possible paths are:\r\n\r\nPath1: AB-BC, \r\nPath2: AD-DC\r\n*/\r\n\r\nclass Solution {\r\n  public static void main(String[] args) {\r\n  }\r\n}\r\n","Sum":"// To execute Java, please define \"static void main\" on a class\r\n// named Solution.\r\n\r\n/*\r\nYou are given an array of positive integers. Your goal is to return a pair of numbers that sum up to 10. If there are no such numbers, return -1, -1 for the pair\r\n\r\nExample:\r\ninputArray= [10, 2, 1, 19, 2, 8]\r\nOutput: 2, 8\r\n*/\r\n\r\nclass Solution {\r\n  public static void main(String[] args) {\r\n  }\r\n}\r\n","[Web - JS] Link Markup Generation":"/*\r\n  Complete the below function so that\r\n  given a string of comma-delimited names\r\n  will generate links of the form\r\n\r\n  \u003Ca href=\"http://klout.com/name\"\u003Ename\u003C/a\u003E\r\n\r\n  So for the following input, names = 'frank, bob, chris'\r\n  we expect:\r\n\r\n  \u003Ca href=\"http://klout.com/frank\"\u003Efrank\u003C/a\u003E\r\n  \u003Ca href=\"http://klout.com/bob\"\u003Ebob\u003C/a\u003E\r\n  \u003Ca href=\"http://klout.com/chris\"\u003Echris\u003C/a\u003E\r\n*/\r\n\r\nfunction generateLinks(names) {\r\n\r\n}","DevOps - HAProxy grok":"# the current HAPROXYHTTP line below is incorrect, create a new HAPROXYHTTPFIXED line with the proper variables so it passes grok\r\n\r\n\r\nHAPROXYDATE %{MONTHDAY}/%{MONTH}/%{YEAR}:%{TIME}.%{INT:milliseconds}\r\nHAPROXYTERMINATIONSTATE [CAPRIcs-][RQCHDLT-][NIDV-][NIPRD-]\r\n\r\n# parse an haproxy 'httplog' line in the following format:\r\n# Jan 16 09:40:32 localhost haproxy[11875]: 50.18.151.196:37202 [16/Jan/2012:09:40:32.253] http-in servers/a0106 0/0/0/104/+104 200 +194 - - ---- 14/14/14/10/0 0/0 {114} \"POST /api/klout.json?key=xxxxxxxxxxxxx\u0026\u0026apikey=xxxxxxxxxxxxx HTTP/1.1\"\r\n\r\nHAPROXYHTTP %{SYSLOGDATE:date} %{IPORHOST:server} %{SYSLOGPROG}: %{IP:clientip}:%{INT:clientport} \\[%{HAPROXYDATE:haproxydate}\\] %{NOTSPACE:proxyname} %{NOTSPACE}/%{IPORHOST:backend} %{INT:time_request}/%{INT:time_queue}/%{INT:time_backend_connect}/%{INT:time_backend_response}/%{INT:time_duration} %{INT:response} %{INT:bytes} - - %{HAPROXYTERMINATIONSTATE:terminationstate} %{INT:actconn}/%{INT:feconn}/%{INT:beconn}/%{INT:srvconn} %{INT:srv_queue}/%{INT:backend_queue} \"%{WORD:verb} %{URIPATHPARAM:request} HTTP/%{NUMBER:version}\"","DevOps - Puppet heartbeat":"# Given the following files, create an entry for your site.pp that creates heartbeat between the following two servers that marks servers as dead after 5 seconds:\r\n# sql1a.klout.pvt 10.1.1.1 (bond0)\r\n# sql1b.klout.pvt 10.1.1.2 (bond0)\r\n\r\n\r\n#modules/heartbeat/init.pp\r\n\r\nclass heartbeat::server {\r\n  package {\r\n    \"heartbeat\":\r\n      ensure =\u003E \"installed\";\r\n  }\r\n  define cluster($node1,$node2,$logfacility,$auto_failback,$auth_key,$peer_ip,$nic) {    \r\n    file {\r\n        \"/etc/ha.d/\":\r\n           ensure =\u003E directory;\r\n        \"/etc/ha.d/ha.cf\":\r\n           content =\u003E template(\"heartbeat/ha.cf.erb\"),\r\n           owner   =\u003E 'root',\r\n           group   =\u003E 'root',\r\n           mode    =\u003E 640;\r\n        \"/etc/ha.d/authkeys\":\r\n           content =\u003E template(\"heartbeat/authkeys.erb\"),\r\n           owner   =\u003E 'root',\r\n           group   =\u003E 'root',\r\n           mode    =\u003E 600;\r\n    }\r\n  }\r\n  service {\r\n    'heartbeat':\r\n      enable  =\u003E true,\r\n      ensure  =\u003E running,\r\n  }\r\n}\r\n\r\n# modules/heartbeat/templates/authkeys.rb\r\nauth 2\r\n2 sha1 \u003C%= auth_key %\u003E\r\n\r\n# modules/heartbeat/templates/ha.cf.rb\r\nlogfacility \u003C%= logfacility %\u003E\r\nkeepalive 2\r\ndeadtime 10\r\nucast \u003C%= nic %\u003E \u003C%= peer_ip %\u003E\r\nauto_failback \u003C%= auto_failback %\u003E\r\n\r\nnode \u003C%= node1 %\u003E \u003C%= node2 %\u003E\r\n","Hadoop join on value":"// To execute Java, please define \"static void main\" on a class\r\n// named Solution.\r\n\r\n/*\r\n  Input Data set 1 : \r\n  key = K1\r\n  value = [ID1, ID2, ID3]\r\n\r\n  Input Data set 2 :\r\n  key = ID1\r\n  value = NAME1\r\n\r\n  Output Expected :\r\n  key = K1\r\n  value = [NAME1, NAME2, NAME3]\r\n\r\n  Data set examples are just to show the format. \r\n  The list can have more entries\r\n*/\r\n\r\nclass Solution {\r\n  public static void main(String[] args) {\r\n  }\r\n}\r\n","Binary Tree":"y // To execute Java, please define \"static void main\" on a class\r\n// named Solution.\r\n\r\n/*\r\nYou are given a root node of a binary tree. Implement the function below to determine if a given tree is a binary search tree.\r\n\r\nSample Input:\r\n\r\n1) Input:\r\n    10\r\n  5   12 \r\n\r\nResult: True\r\n\r\n2) Input:\r\n      10\r\n   12  14\r\nResult: False\r\n\r\nboolean isBinaryTree(Node n) {\r\n\r\n}\r\n*/\r\n\r\nclass Solution {\r\n  public static void main(String[] args) {\r\n  }\r\n}\r\n","Debugging a web-based application":"You're working on a web-based HR application. It's in development, and has the most basic features implemented - you can browse to an employee and see their details. Today your colleague coded a new page that displays, for a manager, the list of employees that report to her. Your colleague has just run this page on his local dev server with his test database, but when he navigates to this page for a manager in the database, doesn't see any employees for this manager. He thinks the code is correct. He's asked for your help in debugging the page.\r\n\r\nWhat steps will you take to determine what's causing the problem?\r\n\r\n","Top Influencers":"// To execute Java, please define \"static void main\" on a class\r\n// named Solution.\r\n\r\n/*\r\nYou have data in two directories:\r\nDirectory 1: User name to influencer mapping\r\nData Format:\r\nUser1:User2,User3,User4,User5\r\nUser10:User1,User2\r\n...\r\n\r\nDirectory 2: User to score mapping\r\nUser1: 20\r\nUser2: 30\r\n...\r\n\r\nWrite code to produce ranked influencers for each user sorted by score.\r\n\r\nThe data in both these directories are in the order of gigabytes. Some users will have millions of influencers\r\n\r\n\r\nExample:\r\n\r\nInputs:\r\na) \r\nfoo:fii,bar,baz\r\nfii:foo,baz,doo\r\n\r\nb)\r\nfoo: 20\r\nfii: 33\r\nbar: 50\r\nbaz: 65\r\ndoo: 90\r\n\r\nOutput:\r\nfoo: baz, bar,fii\r\nfii: doo,baz, foo\r\n*/\r\n\r\nclass Solution {\r\n  public static void main(String[] args) {\r\n  }\r\n}\r\n","Reverse Word Order":"// To execute Java, please define \"static void main\" on a class\r\n// named Solution.\r\n\r\n/*\r\nGiven a string as input \", write a method that reverses the word order of the string.\r\n\r\n// example reverse(\"I like Klout\") =\u003E \"Klout like I\"\r\n*/\r\n\r\nclass Solution {\r\n  public static void main(String[] args) {\r\n  }\r\n}\r\n","Median Response Time":"// To execute Java, please define \"static void main\" on a class\r\n// named Solution.\r\n\r\n/*\r\nYou have a webservice that has two end points\r\n\r\n1. acceptResponseTime that takes in an integer\r\n2. medianResponseTime that returns median of response time received so far using acceptResponseTime endpoint\r\n\r\n\r\nHow will you implement the two end points? What data structure will you use to store the numbers and how will you retrieve median?\r\n*/\r\n\r\nclass Solution {\r\n  public static void main(String[] args) {\r\n  }\r\n}\r\n","Quad Tree":"// To execute Java, please define \"static void main\" on a class\r\n// named Solution.\r\n\r\n/*\r\nQuad tree. \r\nExample of the quad tree is shown here: http://graphics.cs.niu.edu/projects/regview/quadtree1.jpg\r\nQuad trees are usefull if you are dealing with images where large regions are covered with same colour for example.\r\n\r\n1) Design class you would use to represent quad tree (only black/white colours).\r\n2) Implement intersection function using class you designed. Intersection of two images (QuadTrees) result in image (QuadTree) where result image will have black nodes only two imput images had black nodes:\r\n\r\n          WB    BW   WW\r\nExample:\r\n          BB /\\ WB = WB\r\n*/\r\n\r\nclass Solution {\r\n  public static void main(String[] args) {\r\n\r\n  }\r\n}\r\n","Automate GET request":"''' \r\nwrite a script that will read a csv file containing a list of user ids and append them to a get request.  Validate the response for the id you are searching for.\r\n'''\r\n","Random byte from a stream":"// To execute Java, please define \"static void main\" on a class\r\n// named Solution.\r\n\r\n/* \r\nYou have a stream of bytes from which you can only read one byte at a time. Your goal is to design an algorithm to get a random byte from the stream. The algorithm you design should ensure that each byte has the same probability of being picked.\r\n*/\r\n\r\nclass Solution {\r\n  public static void main(String[] args) {\r\n\r\n  }\r\n}\r\n","Mobile - Getter / Setter":"/*\r\nWrite a subclass of NSObject that implements a retained property for an NSString object, without using @synthesize or ARC.\r\n*/\r\n","Mobile - iOS":"/* \r\nHow would you implement encapsulated, reusable code for the commonplace \"pull to refresh\" interaction feature in an iOS application? Write the header definitions for a class (or classes) to illustrate your design.\r\n*/\r\n","Mobile - JSON API client":"// Clang 3.5 running with ARC and non-fragile ABI\r\n\r\n/*\r\nSay we're writing an application which allows users to enter a Twitter handle, looks them up on Klout, and shows their Klout profile. Klout has a server-side API which returns JSON dictionaries for the user profile information given a Twitter handle. Another developer is implementing the user-facing components such as the navigation, profile display, etc; your task is to write the API client which interacts with the Klout server-side API and provides the UI developer with the necessary information.\r\n\r\nNote: don't worry about JSON parsing, leave that to a library (JSONKit for instance).\r\n\r\nBonus points: use blocks instead of a delegate protocol for callbacks to the UI code.\r\n\r\nBonus points: make your implementation extensible to other API methods.\r\n*/\r\n\r\n#import \u003CFoundation/Foundation.h\u003E\r\n#import \u003Cstdio.h\u003E\r\n\r\nint main (int argc, const char * argv[])\r\n{\r\n  @autoreleasepool {\r\n    NSString* hello = @\"Hello, World!\";\r\n    for (int i = 1; i \u003C= 5; i++) {\r\n      printf(\"%s #%d\\n\", [hello UTF8String], i);\r\n    }\r\n  }\r\n}\r\n","DevOps - Apache Log Counts":"'''\r\nGiven a standard apache2 logfile, formatted like this: \r\n\r\n76.214.44.192 - - [15/Feb/2011:23:44:31 -0800] \"GET / HTTP/1.1\" 200 1103 \"-\" \"Mozilla/5.0 (X11; U; Linux x86_64; en-US; rv:1.9.1.16) Gecko/20110107 Iceweasel/3.5.16 (like Firefox/3.5.16)\"\r\n76.214.44.192 - - [15/Feb/2011:23:44:41 -0800] \"GET /pics/web/thumbs/thumb_DSC_4618.JPG HTTP/1.1\" 200 54819 \"http://teletweety.com/pics/web/\" \"Mozilla/5.0 (X11; U; Linux x86_64; en-US; rv:1.9.1.16) Gecko/20110107 Iceweasel/3.5.16 (like Firefox/3.5.16)\"\r\n\r\nhow can we conveniently see the top ten IP addresses and how many times each of those appeared?\r\n'''\r\n","DevOps - Hadoop Health Status":"Given this output from a Hadoop NameNode health check, do you see any issues?\r\n\r\nroot@cluster1~# hadoop fsck / -blocks\r\n...\r\n...\r\n....................................................................................................\r\n....................................................................................................\r\n....................................................................................................\r\n....................................................................................................\r\n......................Status: HEALTHY\r\n Total size:    11936366078530 B (Total open files size: 496 B)\r\n Total dirs:    19238\r\n Total files:   227922 (Files currently being written: 16)\r\n Total blocks (validated):  114177 (avg. block size 104542649 B) (Total open file blocks (not validated): 16)\r\n Minimally replicated blocks:   114177 (100.0 %)\r\n Over-replicated blocks:    0 (0.0 %)\r\n Under-replicated blocks:   5137 (4.5 %)\r\n Mis-replicated blocks:     2626 (2.3 %)\r\n Default replication factor:    3\r\n Average block replication: 3.0856478\r\n Corrupt blocks:        0\r\n Missing replicas:      0 (0.0 %)\r\n Number of data-nodes:      14\r\n Number of racks:       1\r\nFSCK ended at Thu Apr 12 20:35:48 UTC 2012 in 1256 milliseconds\r\n\r\n\r\nThe filesystem under path '/' is HEALTHY\r\n","DevOps - Puppet manifest debugging":"class hadoop::config {\r\n  require hadoop::install\r\n  require hadoop::params\r\n\r\n  file { \"/etc/hadoop-0.20/conf.klout\":\r\n    require =\u003E Package['hadoop-0.20'],\r\n    ensure =\u003E directory,\r\n    owner =\u003E 'root';\r\n    group =\u003E 'root',\r\n    mode =\u003E 0755\r\n  }\r\n\r\n  file { \"/etc/hadoop-0.20/conf\":\r\n    require =\u003E File['/etc/hadoop-0.20/conf.klout'],\r\n    ensure =\u003E link,\r\n    target =\u003E '/etc/hadoop-0.20/conf.klout'\r\n  }\r\n\r\n  file { \"/etc/hadoop-0.20/conf.klout/hdfs-site.xml\":\r\n    require =\u003E File['/etc/hadoop-0.20/conf.klout'],\r\n    source =\u003E template('hadoop/hdfs-site.xml.erb');\r\n    owner =\u003E 'root',\r\n    group =\u003E 'root',\r\n    mode =\u003E '0644'\r\n  }\r\n  \r\n  package { 'hadoop-0.20-secondarynamenode': \r\n    ensure =\u003E installed\r\n  }\r\n\r\n  service { 'hadoop-0.20-secondarynamenode':\r\n    require =\u003E Package['hadoop-0.20-secondarynamenode'],\r\n    enable  =\u003E true\r\n  }\r\n\r\n  $array_of_volumes = split('/data1,/data2,/data3', ',')\r\n\r\n  define format {\r\n    file { \"${name}/hadoop\": \r\n      require =\u003E [ Package['hadoop-0.20'] ],\r\n      ensure  =\u003E directory,\r\n      owner   =\u003E 'hdfs',\r\n      group   =\u003E 'hadoop',\r\n      mode    =\u003E 0755\r\n    }\r\n  }\r\n\r\n}","[Web] Build a login form":"\u003C--\r\n|-----------------------------------------------|\r\n|                                               |\r\n|           username: ___________               |\r\n|                 pw: ___________               |\r\n|                                               |\r\n|-----------------------------------------------|\r\n\r\n1) What would the CSS/HTML for this form look like?\r\n\r\n2) Now capture the form submission event and submit via AJAX, only if the password is \u003E 5 characters.\r\n--\u003E\r\n\r\n","[Web - JS] Closures":"// What will this output?\r\n\r\nfor (var i = 0, ii = 10; i \u003C ii; ++i) {\r\n    setTimeout(function () {\r\n        console.log(i * 10);\r\n    }, i * 10);\r\n}\r\n  ","[Web - JS] Implement document.getElementByClassName()":"// Implement document.getElementByClassName without using any libraries.\r\n","[Web - CSS] Implement Two-Tone Column Layout":"/*\r\n|----------------|--------------------------|\r\n|                |//////////////////////////|\r\n|                |//////////////////////////|\r\n|                |//////////////////////////|\r\n|                |//////////////////////////|\r\n|-------------------------------------------|\r\n|...........................................|\r\n|...........................................|\r\n|...........................................|\r\n|...........................................|\r\n|...........................................|\r\n|-------------------------------------------|\r\n\r\nThe above is a fluid two-column layout, above a single one column layout. Top left grid should have a white background, the top right gray, and the bottom black. What would the markup and CSS for this look like?\r\n*/\r\n","Autocomplete":"// To execute Java, please define \"static void main\" on a class\r\n// named Solution.\r\n\r\n/*\r\nAutocomplete functionality is used anywhere from bash autocomplete, to google search, e-mail clients etc. Say you have large file containing list (can not fit in memory efficiently as sorted string list), of words/commands that are candidates for autocomplete. Example:\r\n\r\n sh\u003Eg \u003Cpress TAB\u003E =\u003E see suggestions\r\n g++ gd2togif genstrings git-upload-pack ... ’\r\n*/ \r\n\r\nclass Solution {\r\n  public static void main(String[] args) {\r\n  }\r\n}\r\n","DevOps - Hadoop - Corrupt HDFS System":"[klout@hadoop01 ~]$ sudo -u hdfs hadoop fsck / -files -blocks -locations\r\nFSCK started by hdfs (auth:SIMPLE) from /10.1.1.132 for path / at Fri May 25 15:40:00 PDT 2012 / \u003Cdir\u003E\r\n...\r\n/hbase/usertable/a8a0829c1661099e80f4d619a4a8b77d \u003Cdir\u003E /hbase/usertable/a8a0829c1661099e80f4d619a4a8b77d/.regioninfo 866 bytes, 1 block(s): OK\r\n0. blk_3620806743122792301_938094 len=866 repl=3 [10.1.1.140:1004, 10.1.1.135:1004, 10.1.1.137:1004]\r\n/hbase/usertable/a8a0829c1661099e80f4d619a4a8b77d/.tmp \u003Cdir\u003E /hbase/usertable/a8a0829c1661099e80f4d619a4a8b77d/value \u003Cdir\u003E /hbase/usertable/a8a0829c1661099e80f4d619a4a8b77d/value/7404071833681777848 544152382 bytes, 9 block(s): OK 0. blk_-4483752819038443375_961039 len=67108864 repl=3 [10.1.1.136:1004, 10.1.1.132:1004, 10.1.1.135:1004] 1. blk_-9090271957364756334_961045 len=67108864 repl=3 [10.1.1.134:1004, 10.1.1.139:1004, 10.1.1.135:1004] 2. blk_-8663933707558762843_961045 len=67108864 repl=3 [10.1.1.136:1004, 10.1.1.133:1004, 10.1.1.135:1004] 3. blk_-243708713912215859_961046 len=67108864 repl=3 [10.1.1.131:1004, 10.1.1.136:1004, 10.1.1.135:1004]\r\n4. blk_8889057014155026774_961047 len=67108864 repl=3 [10.1.1.136:1004, 10.1.1.135:1004, 10.1.1.137:1004] 5. blk_-8973735748029935709_961048 len=67108864 repl=3 [10.1.1.131:1004, 10.1.1.136:1004, 10.1.1.135:1004] 6. blk_2457643535020786460_961048 len=67108864 repl=3 [10.1.1.131:1004, 10.1.1.133:1004, 10.1.1.135:1004] 7. blk_-903758822242531603_961049 len=67108864 repl=3 [10.1.1.131:1004, 10.1.1.133:1004, 10.1.1.135:1004] 8. blk_4446759321669624116_961051 len=7281470 repl=3 [10.1.1.137:1004, 10.1.1.132:1004, 10.1.1.135:1004] ...\r\n/user/klout/job17/part-00077 12500000000 bytes, 94 block(s): Under replicated blk_-3488281800025438592_848 Under replicated blk_-1241890260240671450_84813. Target Replicas is 3 but found 2 replica(s).\r\nUnder replicated blk_2951198656702268751_84813. Target Replicas is 3 but found 2 replica(s).\r\nUnder replicated blk_2030140999874428901_84815. Target Replicas is 3 but found 2 replica(s).\r\n...\r\n0. blk_2806218775441650422_84812 len=134217728 repl=3 [10.1.1.136:1004, 10.1.1.135:1004, 10.1.1.139:1004] 1. blk_-7693415728714491276_84812 len=134217728 repl=3 [10.1.1.140:1004, 10.1.1.139:1004, 10.1.1.137:1004] 2. blk_-4047400381436606420_84812 len=134217728 repl=3 [10.1.1.136:1004, 10.1.1.134:1004, 10.1.1.139:1004] 3. blk_6268554594414163694_84812 len=134217728 repl=3 [10.1.1.132:1004, 10.1.1.136:1004, 10.1.1.139:1004] 4. blk_437166175380747476_84813 len=134217728 repl=3 [10.1.1.138:1004, 10.1.1.132:1004, 10.1.1.139:1004] 5. blk_-3373529866329232880_84814 len=134217728 repl=2 [10.1.1.137:1004, 10.1.1.139:1004]\r\n6. blk_-6567492536488398932_84815 len=134217728 repl=3 [10.1.1.137:1004, 10.1.1.132:1004, 10.1.1.139:1004] 7. blk_-5068856556266368904_84815 len=134217728 repl=3 [10.1.1.138:1004, 10.1.1.137:1004, 10.1.1.139:1004] ...\r\n/user/klout/job18/part-00018: CORRUPT block blk_-7164267453697813302\r\nMISSING 125 blocks of total size 16648440800 B\r\n0. blk_2190128488155518392_86488 len=134217728 MISSING! 1. blk_6387562258768894352_86505 len=134217728 MISSING! 2. blk_-2266931705749612258_86516 len=134217728 MISSING! ...\r\nStatus: CORRUPT\r\nTotal size: 9113209169518 B (Total open files size: 372 B)\r\nTotal dirs: 9206\r\nTotal files: 14649 (Files currently being written: 10)\r\nTotal blocks (validated): 87640 (avg. block size 103984586 B) (Total open file blocks (not validated):\r\n********************************\r\nCORRUPT FILES:    21\r\nMISSING BLOCKS: 3846\r\nMISSING SIZE:       514487882400 B\r\nCORRUPT BLOCKS: 3846\r\n********************************\r\nMinimally replicated blocks: 83794 (95.611595 %) 0 (0.0 %)\r\nOver-replicated blocks:      0 (0.0 %)\r\nUnder-replicated blocks:     4684 (5.3445916 %) 0 (0.0 %)    \r\nMis-replicated blocks:       0 (0.0 %)\r\nDefault replication factor:  3\r\nAverage block replication:   2.1531606\r\nCorrupt blocks:              3846\r\nMissing replicas:            4684 (2.4822075 %)\r\nNumber of data-nodes:        9\r\nNumber of racks:             1\r\nFSCK ended at Fri May 25 17:20:34 PDT 2012 in 573 milliseconds","DevOps - Hbase Exception - 1 - Client":"Monitoring Graphs\r\n----\r\nhttps://s3.amazonaws.com/uploads.hipchat.com/10509/78278/d9kmuo1d7x2bwwt/histogram.png\r\n\r\nHBase Client Logs\r\n----\r\n8:06:24.575 PM\t\r\n2012-05-17 20:06:24,575  WARN hbase-zk-system-akka.actor.default-dispatcher-12 [org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation:1587] Failed all from region=combinedScore,55714285714285680,1332543412274.e9846bb99adec8ab71847594abd9eeee., hostname=hbase2-rs8.klout, port=60020\r\njava.util.concurrent.ExecutionException: java.io.IOException: Call to hbase2-rs8.klout/10.1.6.8:60020 failed on local exception: org.apache.hadoop.hbase.ipc.HBaseClient$CallTimeoutException: Call id=7949070, waitTime=90205, rpcTimetout=60000\r\n\tat java.util.concurrent.FutureTask$Sync.innerGet(FutureTask.java:222) ~[na:1.6.0_31]\r\n\tat java.util.concurrent.FutureTask.get(FutureTask.java:83) ~[na:1.6.0_31]\r\n\tat org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.processBatchCallback(HConnectionManager.java:1557) [hbase-0.92.1-cdh4.0.0b2.jar:na]\r\n\tat org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.processBatch(HConnectionManager.java:1409) [hbase-0.92.1-cdh4.0.0b2.jar:na]\r\n\tat org.apache.hadoop.hbase.client.HTable.batch(HTable.java:746) [hbase-0.92.1-cdh4.0.0b2.jar:na]\r\n\tat org.apache.hadoop.hbase.client.HTable.get(HTable.java:715) [hbase-0.92.1-cdh4.0.0b2.jar:na]\r\n\tat org.apache.hadoop.hbase.client.HTablePool$PooledHTable.get(HTablePool.java:371) [hbase-0.92.1-cdh4.0.0b2.jar:na]\r\n\tat com.klout.playful2.hbase.RealHBaseClient$$anonfun$readColumnBatch$1$$anonfun$7.apply(hbase.scala:167) [classes/:na]\r\n\tat com.klout.playful2.hbase.RealHBaseClient$$anonfun$readColumnBatch$1$$anonfun$7.apply(hbase.scala:165) [classes/:na]\r\n\tat com.klout.playful2.hbase.HBaseProcessorActor.com$klout$playful2$hbase$HBaseProcessorActor$$hbaseOperation(actor.scala:355) [classes/:na]\r\n\tat com.klout.playful2.hbase.HBaseProcessorActor$$anonfun$12$$anonfun$apply$2$$anonfun$apply$3.apply(actor.scala:341) [classes/:na]\r\n\tat com.klout.playful2.hbase.HBaseProcessorActor$$anonfun$12$$anonfun$apply$2$$anonfun$apply$3.apply(actor.scala:341) [classes/:na]\r\n\tat com.klout.playful2.hbase.HBaseProcessorActor$$anonfun$12$$anonfun$apply$2$$anonfun$apply$4.apply(actor.scala:341) [classes/:na]\r\n\tat com.klout.playful2.hbase.HBaseProcessorActor$$anonfun$12$$anonfun$apply$2$$anonfun$apply$4.apply(actor.scala:341) [classes/:na]\r\n\tat com.klout.playful2.services.Service$.service(services.scala:36) [classes/:na]\r\n\tat com.klout.playful2.hbase.HBaseProcessorActor$$anonfun$12$$anonfun$apply$2.apply(actor.scala:340) [classes/:na]\r\n\tat com.klout.playful2.hbase.HBaseProcessorActor$$anonfun$12$$anonfun$apply$2.apply(actor.scala:340) [classes/:na]\r\n\tat akka.dispatch.Future$$anon$3.liftedTree1$1(Future.scala:195) [akka-actor.jar:2.0.2]\r\n\tat akka.dispatch.Future$$anon$3.run(Future.scala:194) [akka-actor.jar:2.0.2]\r\n\tat akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:94) [akka-actor.jar:2.0.2]\r\n\tat akka.jsr166y.ForkJoinTask$AdaptedRunnableAction.exec(ForkJoinTask.java:1381) [akka-actor.jar:2.0.2]\r\n\tat akka.jsr166y.ForkJoinTask.doExec(ForkJoinTask.java:259) [akka-actor.jar:2.0.2]\r\n\tat akka.jsr166y.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:975) [akka-actor.jar:2.0.2]\r\n\tat akka.jsr166y.ForkJoinPool.runWorker(ForkJoinPool.java:1479) [akka-actor.jar:2.0.2]\r\n\tat akka.jsr166y.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104) [akka-actor.jar:2.0.2]\r\njava.io.IOException: Call to hbase2-rs8.klout/10.1.6.8:60020 failed on local exception: org.apache.hadoop.hbase.ipc.HBaseClient$CallTimeoutException: Call id=7949070, waitTime=90205, rpcTimetout=60000\r\n\tat org.apache.hadoop.hbase.ipc.HBaseClient.wrapException(HBaseClient.java:953) ~[hbase-0.92.1-cdh4.0.0b2.jar:na]\r\n\tat org.apache.hadoop.hbase.ipc.HBaseClient.call(HBaseClient.java:922) ~[hbase-0.92.1-cdh4.0.0b2.jar:na]\r\n\tat org.apache.hadoop.hbase.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:150) ~[hbase-0.92.1-cdh4.0.0b2.jar:na]\r\n\tat $Proxy8.multi(Unknown Source) ~[na:na]\r\n\tat org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation$3$1.call(HConnectionManager.java:1386) ~[hbase-0.92.1-cdh4.0.0b2.jar:na]\r\n\tat org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation$3$1.call(HConnectionManager.java:1384) ~[hbase-0.92.1-cdh4.0.0b2.jar:na]\r\n\tat org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.getRegionServerWithoutRetries(HConnectionManager.java:1365) [hbase-0.92.1-cdh4.0.0b2.jar:na]\r\n\tat org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation$3.call(HConnectionManager.java:1383) ~[hbase-0.92.1-cdh4.0.0b2.jar:na]\r\n\tat org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation$3.call(HConnectionManager.java:1381) ~[hbase-0.92.1-cdh4.0.0b2.jar:na]\r\n\tat java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303) ~[na:1.6.0_31]\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:138) ~[na:1.6.0_31]\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886) ~[na:1.6.0_31]\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908) ~[na:1.6.0_31]\r\n\tat java.lang.Thread.run(Thread.java:662) ~[na:1.6.0_31]\r\norg.apache.hadoop.hbase.ipc.HBaseClient$CallTimeoutException: Call id=7949070, waitTime=90205, rpcTimetout=60000\r\n\tat org.apache.hadoop.hbase.ipc.HBaseClient$Connection.cleanupCalls(HBaseClient.java:684) ~[hbase-0.92.1-cdh4.0.0b2.jar:na]\r\n\tat org.apache.hadoop.hbase.ipc.HBaseClient$Connection.receiveResponse(HBaseClient.java:613) ~[hbase-0.92.1-cdh4.0.0b2.jar:na]\r\n\tat org.apache.hadoop.hbase.ipc.HBaseClient$Connection.run(HBaseClient.java:505) ~[hbase-0.92.1-cdh4.0.0b2.jar:na]","DevOps - Hbase Exception - 2 - RegionServer":"RegionServer Log\r\n---\r\n2012-07-17 20:05:10,821 DEBUG org.apache.hadoop.hbase.replication.regionserver.ReplicationSource: currentNbOperations:0 and seenEntries:0 and size: 0\r\n2012-07-17 20:05:20,821 DEBUG org.apache.hadoop.hbase.replication.regionserver.ReplicationSource: Opening log for replication hbase2-rs5.klout%2C60020%2C1341600119781.1341600120883 at 124\r\n2012-07-17 20:05:20,836 DEBUG org.apache.hadoop.hbase.replication.regionserver.ReplicationSource: currentNbOperations:0 and seenEntries:0 and size: 0\r\n2012-07-17 20:05:10,821 DEBUG org.apache.hadoop.hbase.replication.regionserver.ReplicationSource: Nothing to replicate, sleeping 1000 times 10\r\n2012-07-17 20:05:20,836 DEBUG org.apache.hadoop.hbase.replication.regionserver.ReplicationSource: Nothing to replicate, sleeping 1000 times 10\r\n2012-07-17 20:05:30,836 DEBUG org.apache.hadoop.hbase.replication.regionserver.ReplicationSource: Opening log for replication hbase2-rs5.klout%2C60020%2C1341600119781.1341600120883 at 124\r\n2012-07-17 20:05:30,845 DEBUG org.apache.hadoop.hbase.replication.regionserver.ReplicationSource: currentNbOperations:0 and seenEntries:0 and size: 0\r\n2012-07-17 20:05:30,846 DEBUG org.apache.hadoop.hbase.replication.regionserver.ReplicationSource: Nothing to replicate, sleeping 1000 times 10\r\n2012-07-17 20:05:39,594 INFO org.mortbay.log: org.mortbay.io.nio.SelectorManager$SelectSet@213651ed JVM BUG(s) - injecting delay1 times\r\n2012-07-17 20:05:39,594 INFO org.mortbay.log: org.mortbay.io.nio.SelectorManager$SelectSet@213651ed JVM BUG(s) - recreating selector 1 times, canceled keys 31 times\r\n2012-07-17 20:05:39,898 WARN org.apache.hadoop.hdfs.DFSClient: Failed to connect to /10.1.6.3:50010 for file /hbase/combinedScore/e450dfbe35bfca70cb6561c8e27b16ad/score/78555b34df8649039800e530c6152fd7 for block 1921587107450736544:java.net.SocketTimeoutException: 60000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.1.6.5:45098 remote=/10.1.6.3:50010]\r\n\tat org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)\r\n\tat org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)\r\n\tat org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)\r\n\tat java.io.BufferedInputStream.fill(BufferedInputStream.java:218)\r\n\tat java.io.BufferedInputStream.read(BufferedInputStream.java:237)\r\n\tat java.io.DataInputStream.readInt(DataInputStream.java:370)\r\n\tat org.apache.hadoop.hdfs.DFSClient$RemoteBlockReader.readChunk(DFSClient.java:1489)\r\n\tat org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:237)\r\n\tat org.apache.hadoop.fs.FSInputChecker.fill(FSInputChecker.java:176)\r\n\tat org.apache.hadoop.fs.FSInputChecker.read1(FSInputChecker.java:193)\r\n\tat org.apache.hadoop.fs.FSInputChecker.read(FSInputChecker.java:158)\r\n\tat org.apache.hadoop.hdfs.DFSClient$RemoteBlockReader.read(DFSClient.java:1379)\r\n\tat org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:141)\r\n\tat org.apache.hadoop.hdfs.DFSClient$DFSInputStream.fetchBlockByteRange(DFSClient.java:2278)\r\n\tat org.apache.hadoop.hdfs.DFSClient$DFSInputStream.read(DFSClient.java:2438)\r\n\tat org.apache.hadoop.fs.FSDataInputStream.read(FSDataInputStream.java:46)\r\n\tat org.apache.hadoop.hbase.io.hfile.HFileBlock$AbstractFSReader.readAtOffset(HFileBlock.java:1034)\r\n\tat org.apache.hadoop.hbase.io.hfile.HFileBlock$FSReaderV2.readBlockData(HFileBlock.java:1335)\r\n\tat org.apache.hadoop.hbase.io.hfile.HFileReaderV2.readBlock(HFileReaderV2.java:266)\r\n\tat org.apache.hadoop.hbase.io.hfile.HFileBlockIndex$BlockIndexReader.seekToDataBlock(HFileBlockIndex.java:209)\r\n\tat org.apache.hadoop.hbase.io.hfile.HFileReaderV2$ScannerV2.seekTo(HFileReaderV2.java:519)\r\n\tat org.apache.hadoop.hbase.io.hfile.HFileReaderV2$ScannerV2.seekTo(HFileReaderV2.java:534)\r\n\tat org.apache.hadoop.hbase.regionserver.StoreFileScanner.seekAtOrAfter(StoreFileScanner.java:178)\r\n\tat org.apache.hadoop.hbase.regionserver.StoreFileScanner.seek(StoreFileScanner.java:111)\r\n\tat org.apache.hadoop.hbase.regionserver.StoreFileScanner.seekExactly(StoreFileScanner.java:219)\r\n\tat org.apache.hadoop.hbase.regionserver.StoreScanner.\u003Cinit\u003E(StoreScanner.java:80)\r\n\tat org.apache.hadoop.hbase.regionserver.Store.getScanner(Store.java:1721)\r\n\tat org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.\u003Cinit\u003E(HRegion.java:2865)\r\n\tat org.apache.hadoop.hbase.regionserver.HRegion.instantiateRegionScanner(HRegion.java:1434)\r\n\tat org.apache.hadoop.hbase.regionserver.HRegion.getScanner(HRegion.java:1426)\r\n\tat org.apache.hadoop.hbase.regionserver.HRegion.getScanner(HRegion.java:1402)\r\n\tat org.apache.hadoop.hbase.regionserver.HRegion.get(HRegion.java:3692)\r\n\tat org.apache.hadoop.hbase.regionserver.HRegion.get(HRegion.java:3585)\r\n\tat org.apache.hadoop.hbase.regionserver.HRegionServer.get(HRegionServer.java:1786)\r\n\tat org.apache.hadoop.hbase.regionserver.HRegionServer.multi(HRegionServer.java:3059)\r\n\tat sun.reflect.GeneratedMethodAccessor50.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\r\n\tat java.lang.reflect.Method.invoke(Method.java:597)\r\n\tat org.apache.hadoop.hbase.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:364)\r\n\tat org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:1326)\r\n2012-07-17 20:05:39,985 WARN org.apache.hadoop.ipc.HBaseServer: (responseTooSlow): {\"processingtimems\":60096,\"call\":\"multi(org.apache.hadoop.hbase.client.MultiAction@2ca1db2f), rpc version=1, client version=29, methodsFingerPrint=54742778\",\"client\":\"10.1.4.14:48184\",\"starttimems\":1342555479888,\"queuetimems\":0,\"class\":\"HRegionServer\",\"responsesize\":0,\"method\":\"multi\"}\r\n2012-07-17 20:05:40,846 DEBUG org.apache.hadoop.hbase.replication.regionserver.ReplicationSource: Opening log for replication hbase2-rs5.klout%2C60020%2C1341600119781.1341600120883 at 124\r\n2012-07-17 20:05:40,861 DEBUG org.apache.hadoop.hbase.replication.regionserver.ReplicationSource: currentNbOperations:0 and seenEntries:0 and size: 0\r\n2012-07-17 20:05:40,862 DEBUG org.apache.hadoop.hbase.replication.regionserver.ReplicationSource: Nothing to replicate, sleeping 1000 times 10\r\n2012-07-17 20:06:20,903 DEBUG org.apache.hadoop.hbase.replication.regionserver.ReplicationSource: Opening log for replication hbase2-rs5.klout%2C60020%2C1341600119781.1341600120883 at 124\r\n2012-07-17 20:06:20,917 DEBUG org.apache.hadoop.hbase.replication.regionserver.ReplicationSource: currentNbOperations:0 and seenEntries:0 and size: 0\r\n2012-07-17 20:06:20,917 DEBUG org.apache.hadoop.hbase.replication.regionserver.ReplicationSource: Nothing to replicate, sleeping 1000 times 10\r\n2012-07-17 20:06:28,277 WARN org.apache.hadoop.hdfs.DFSClient: Failed to connect to /10.1.6.3:50010 for file /hbase/combinedScore/e450dfbe35bfca70cb6561c8e27b16ad/score/78555b34df8649039800e530c6152fd7 for block 1921587107450736544:java.net.SocketTimeoutException: 60000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.1.6.5:45954 remote=/10.1.6.3:50010]\r\n\tat org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)\r\n\tat org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)\r\n\tat org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)\r\n\tat java.io.BufferedInputStream.fill(BufferedInputStream.java:218)\r\n\tat java.io.BufferedInputStream.read(BufferedInputStream.java:237)\r\n\tat java.io.DataInputStream.readInt(DataInputStream.java:370)\r\n\tat org.apache.hadoop.hdfs.DFSClient$RemoteBlockReader.readChunk(DFSClient.java:1489)\r\n\tat org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:237)\r\n\tat org.apache.hadoop.fs.FSInputChecker.fill(FSInputChecker.java:176)\r\n\tat org.apache.hadoop.fs.FSInputChecker.read1(FSInputChecker.java:193)\r\n\tat org.apache.hadoop.fs.FSInputChecker.read(FSInputChecker.java:158)\r\n\tat org.apache.hadoop.hdfs.DFSClient$RemoteBlockReader.read(DFSClient.java:1379)\r\n\tat org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:141)\r\n\tat org.apache.hadoop.hdfs.DFSClient$DFSInputStream.fetchBlockByteRange(DFSClient.java:2278)\r\n\tat org.apache.hadoop.hdfs.DFSClient$DFSInputStream.read(DFSClient.java:2438)\r\n\tat org.apache.hadoop.fs.FSDataInputStream.read(FSDataInputStream.java:46)\r\n\tat org.apache.hadoop.hbase.io.hfile.HFileBlock$AbstractFSReader.readAtOffset(HFileBlock.java:1034)\r\n\tat org.apache.hadoop.hbase.io.hfile.HFileBlock$FSReaderV2.readBlockData(HFileBlock.java:1335)\r\n\tat org.apache.hadoop.hbase.io.hfile.HFileReaderV2.readBlock(HFileReaderV2.java:266)\r\n\tat org.apache.hadoop.hbase.io.hfile.HFileBlockIndex$BlockIndexReader.seekToDataBlock(HFileBlockIndex.java:209)\r\n\tat org.apache.hadoop.hbase.io.hfile.HFileReaderV2$ScannerV2.seekTo(HFileReaderV2.java:519)\r\n\tat org.apache.hadoop.hbase.io.hfile.HFileReaderV2$ScannerV2.seekTo(HFileReaderV2.java:534)\r\n\tat org.apache.hadoop.hbase.regionserver.StoreFileScanner.seekAtOrAfter(StoreFileScanner.java:178)\r\n\tat org.apache.hadoop.hbase.regionserver.StoreFileScanner.seek(StoreFileScanner.java:111)\r\n\tat org.apache.hadoop.hbase.regionserver.StoreFileScanner.seekExactly(StoreFileScanner.java:219)\r\n\tat org.apache.hadoop.hbase.regionserver.StoreScanner.\u003Cinit\u003E(StoreScanner.java:80)\r\n\tat org.apache.hadoop.hbase.regionserver.Store.getScanner(Store.java:1721)\r\n\tat org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.\u003Cinit\u003E(HRegion.java:2865)\r\n\tat org.apache.hadoop.hbase.regionserver.HRegion.instantiateRegionScanner(HRegion.java:1434)\r\n\tat org.apache.hadoop.hbase.regionserver.HRegion.getScanner(HRegion.java:1426)\r\n\tat org.apache.hadoop.hbase.regionserver.HRegion.getScanner(HRegion.java:1402)\r\n\tat org.apache.hadoop.hbase.regionserver.HRegion.get(HRegion.java:3692)\r\n\tat org.apache.hadoop.hbase.regionserver.HRegion.get(HRegion.java:3585)\r\n\tat org.apache.hadoop.hbase.regionserver.HRegionServer.get(HRegionServer.java:1786)\r\n\tat org.apache.hadoop.hbase.regionserver.HRegionServer.multi(HRegionServer.java:3059)\r\n\tat sun.reflect.GeneratedMethodAccessor50.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\r\n\tat java.lang.reflect.Method.invoke(Method.java:597)\r\n\tat org.apache.hadoop.hbase.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:364)\r\n\tat org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:1326)\r\n2012-07-17 20:06:28,321 WARN org.apache.hadoop.ipc.HBaseServer: (responseTooSlow): {\"processingtimems\":60050,\"call\":\"multi(org.apache.hadoop.hbase.client.MultiAction@184082a5), rpc version=1, client version=29, methodsFingerPrint=54742778\",\"client\":\"10.1.8.10:52624\",\"starttimems\":1342555528269,\"queuetimems\":0,\"class\":\"HRegionServer\",\"responsesize\":0,\"method\":\"multi\"}\r\n2012-07-17 20:06:28,918 WARN org.apache.hadoop.hdfs.DFSClient: Failed to connect to /10.1.6.3:50010 for file /hbase/combinedScore/e450dfbe35bfca70cb6561c8e27b16ad/score/78555b34df8649039800e530c6152fd7 for block 1921587107450736544:java.net.SocketTimeoutException: 60000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.1.6.5:45958 remote=/10.1.6.3:50010]\r\n\tat org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)\r\n\tat org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)\r\n\tat org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)\r\n\tat java.io.BufferedInputStream.fill(BufferedInputStream.java:218)\r\n\tat java.io.BufferedInputStream.read(BufferedInputStream.java:237)\r\n\tat java.io.DataInputStream.readInt(DataInputStream.java:370)\r\n\tat org.apache.hadoop.hdfs.DFSClient$RemoteBlockReader.readChunk(DFSClient.java:1489)\r\n\tat org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:237)\r\n\tat org.apache.hadoop.fs.FSInputChecker.fill(FSInputChecker.java:176)\r\n\tat org.apache.hadoop.fs.FSInputChecker.read1(FSInputChecker.java:193)\r\n\tat org.apache.hadoop.fs.FSInputChecker.read(FSInputChecker.java:158)\r\n\tat org.apache.hadoop.hdfs.DFSClient$RemoteBlockReader.read(DFSClient.java:1379)\r\n\tat org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:141)\r\n\tat org.apache.hadoop.hdfs.DFSClient$DFSInputStream.fetchBlockByteRange(DFSClient.java:2278)\r\n\tat org.apache.hadoop.hdfs.DFSClient$DFSInputStream.read(DFSClient.java:2438)\r\n\tat org.apache.hadoop.fs.FSDataInputStream.read(FSDataInputStream.java:46)\r\n\tat org.apache.hadoop.hbase.io.hfile.HFileBlock$AbstractFSReader.readAtOffset(HFileBlock.java:1034)\r\n\tat org.apache.hadoop.hbase.io.hfile.HFileBlock$FSReaderV2.readBlockData(HFileBlock.java:1335)\r\n\tat org.apache.hadoop.hbase.io.hfile.HFileReaderV2.readBlock(HFileReaderV2.java:266)\r\n\tat org.apache.hadoop.hbase.io.hfile.HFileBlockIndex$BlockIndexReader.seekToDataBlock(HFileBlockIndex.java:209)\r\n\tat org.apache.hadoop.hbase.io.hfile.HFileReaderV2$ScannerV2.seekTo(HFileReaderV2.java:519)\r\n\tat org.apache.hadoop.hbase.io.hfile.HFileReaderV2$ScannerV2.seekTo(HFileReaderV2.java:534)\r\n\tat org.apache.hadoop.hbase.regionserver.StoreFileScanner.seekAtOrAfter(StoreFileScanner.java:178)\r\n\tat org.apache.hadoop.hbase.regionserver.StoreFileScanner.seek(StoreFileScanner.java:111)\r\n\tat org.apache.hadoop.hbase.regionserver.StoreFileScanner.seekExactly(StoreFileScanner.java:219)\r\n\tat org.apache.hadoop.hbase.regionserver.StoreScanner.\u003Cinit\u003E(StoreScanner.java:80)\r\n\tat org.apache.hadoop.hbase.regionserver.Store.getScanner(Store.java:1721)\r\n\tat org.apache.hadoop.hbase.regionserver.HRegion$RegionScannerImpl.\u003Cinit\u003E(HRegion.java:2865)\r\n\tat org.apache.hadoop.hbase.regionserver.HRegion.instantiateRegionScanner(HRegion.java:1434)\r\n\tat org.apache.hadoop.hbase.regionserver.HRegion.getScanner(HRegion.java:1426)\r\n\tat org.apache.hadoop.hbase.regionserver.HRegion.getScanner(HRegion.java:1402)\r\n\tat org.apache.hadoop.hbase.regionserver.HRegion.get(HRegion.java:3692)\r\n\tat org.apache.hadoop.hbase.regionserver.HRegion.get(HRegion.java:3585)\r\n\tat org.apache.hadoop.hbase.regionserver.HRegionServer.get(HRegionServer.java:1786)\r\n\tat org.apache.hadoop.hbase.regionserver.HRegionServer.multi(HRegionServer.java:3059)\r\n\tat sun.reflect.GeneratedMethodAccessor50.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\r\n\tat java.lang.reflect.Method.invoke(Method.java:597)\r\n\tat org.apache.hadoop.hbase.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:364)\r\n\tat org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:1326)\r\n2012-07-17 20:06:29,238 WARN org.apache.hadoop.ipc.HBaseServer: (responseTooSlow): {\"processingtimems\":60342,\"call\":\"multi(org.apache.hadoop.hbase.client.MultiAction@66e3048), rpc version=1, client version=29, methodsFingerPrint=54742778\",\"client\":\"10.1.4.13:38332\",\"starttimems\":1342555528895,\"queuetimems\":0,\"class\":\"HRegionServer\",\"responsesize\":0,\"method\":\"multi\"}\r\n2012-07-17 20:06:30,918 DEBUG org.apache.hadoop.hbase.replication.regionserver.ReplicationSource: Opening log for replication hbase2-rs5.klout%2C60020%2C1341600119781.1341600120883 at 124\r\n2012-07-17 20:06:30,926 DEBUG org.apache.hadoop.hbase.replication.regionserver.ReplicationSource: currentNbOperations:0 and seenEntries:0 and size: 0\r\n2012-07-17 20:06:30,926 DEBUG org.apache.hadoop.hbase.replication.regionserver.ReplicationSource: Nothing to replicate, sleeping 1000 times 10\r\n2012-07-17 20:06:39,664 INFO org.mortbay.log: org.mortbay.io.nio.SelectorManager$SelectSet@213651ed JVM BUG(s) - injecting delay1 times\r\n2012-07-17 20:06:39,664 INFO org.mortbay.log: org.mortbay.io.nio.SelectorManager$SelectSet@213651ed JVM BUG(s) - recreating selector 1 times, canceled keys 31 times\r\n2012-07-17 20:06:40,926 DEBUG org.apache.hadoop.hbase.replication.regionserver.ReplicationSource: Opening log for replication hbase2-rs5.klout%2C60020%2C1341600119781.1341600120883 at 124\r\n2012-07-17 20:06:40,945 DEBUG org.apache.hadoop.hbase.replication.regionserver.ReplicationSource: currentNbOperations:0 and seenEntries:0 and size: 0\r\n2012-07-17 20:06:40,945 DEBUG org.apache.hadoop.hbase.replication.regionserver.ReplicationSource: Nothing to replicate, sleeping 1000 times 10","DevOps - Hbase Exception - 3 - DataNode":"Kernel Logs\r\n----\r\nJul 17 19:20:05 hbase2-rs3 kernel: [9723432.505880] ata6: hard resetting link\r\nJul 17 19:20:06 hbase2-rs3 kernel: [9723432.847965] ata6: SATA link up 3.0 Gbps (SStatus 123 SControl 300)\r\nJul 17 19:20:06 hbase2-rs3 kernel: [9723432.850761] ata6.00: configured for UDMA/133\r\nJul 17 19:20:06 hbase2-rs3 kernel: [9723432.850769] ata6.00: device reported invalid CHS sector 0\r\nJul 17 19:20:06 hbase2-rs3 kernel: [9723432.850772] ata6.00: device reported invalid CHS sector 0\r\nJul 17 19:20:06 hbase2-rs3 kernel: [9723432.850775] ata6.00: device reported invalid CHS sector 0\r\nJul 17 19:20:06 hbase2-rs3 kernel: [9723432.850778] ata6.00: device reported invalid CHS sector 0\r\nJul 17 19:20:06 hbase2-rs3 kernel: [9723432.850781] ata6.00: device reported invalid CHS sector 0\r\nJul 17 19:20:06 hbase2-rs3 kernel: [9723432.850784] ata6.00: device reported invalid CHS sector 0\r\nJul 17 19:20:06 hbase2-rs3 kernel: [9723432.850787] ata6.00: device reported invalid CHS sector 0\r\nJul 17 19:20:06 hbase2-rs3 kernel: [9723432.850790] ata6.00: device reported invalid CHS sector 0\r\nJul 17 19:20:06 hbase2-rs3 kernel: [9723432.850793] ata6.00: device reported invalid CHS sector 0\r\nJul 17 19:20:06 hbase2-rs3 kernel: [9723432.850796] ata6.00: device reported invalid CHS sector 0\r\nJul 17 19:20:06 hbase2-rs3 kernel: [9723432.850799] ata6.00: device reported invalid CHS sector 0\r\nJul 17 19:20:06 hbase2-rs3 kernel: [9723432.850802] ata6.00: device reported invalid CHS sector 0\r\nJul 17 19:20:06 hbase2-rs3 kernel: [9723432.850805] ata6.00: device reported invalid CHS sector 0\r\nJul 17 19:20:06 hbase2-rs3 kernel: [9723432.850807] ata6.00: device reported invalid CHS sector 0\r\nJul 17 19:20:06 hbase2-rs3 kernel: [9723432.850817] ata6.00: device reported invalid CHS sector 0\r\nJul 17 19:20:06 hbase2-rs3 kernel: [9723432.850819] ata6.00: device reported invalid CHS sector 0\r\nJul 17 19:20:06 hbase2-rs3 kernel: [9723432.850821] ata6.00: device reported invalid CHS sector 0\r\nJul 17 19:20:06 hbase2-rs3 kernel: [9723432.850873] ata6: EH complete\r\nJul 17 19:20:39 hbase2-rs3 kernel: [9723465.782463] ata6: hard resetting link\r\nJul 17 19:20:39 hbase2-rs3 kernel: [9723466.127558] ata6: SATA link up 3.0 Gbps (SStatus 123 SControl 300)\r\nJul 17 19:20:39 hbase2-rs3 kernel: [9723466.130107] ata6.00: configured for UDMA/133\r\nJul 17 19:20:39 hbase2-rs3 kernel: [9723466.130116] ata6.00: device reported invalid CHS sector 0\r\nJul 17 19:20:39 hbase2-rs3 kernel: [9723466.130120] ata6.00: device reported invalid CHS sector 0\r\nJul 17 19:20:39 hbase2-rs3 kernel: [9723466.130123] ata6.00: device reported invalid CHS sector 0\r\nJul 17 19:20:39 hbase2-rs3 kernel: [9723466.130126] ata6.00: device reported invalid CHS sector 0\r\nJul 17 19:20:39 hbase2-rs3 kernel: [9723466.130129] ata6.00: device reported invalid CHS sector 0\r\nJul 17 19:20:39 hbase2-rs3 kernel: [9723466.130132] ata6.00: device reported invalid CHS sector 0\r\nJul 17 19:20:39 hbase2-rs3 kernel: [9723466.130135] ata6.00: device reported invalid CHS sector 0\r\nJul 17 19:20:39 hbase2-rs3 kernel: [9723466.130139] ata6.00: device reported invalid CHS sector 0\r\nJul 17 19:20:39 hbase2-rs3 kernel: [9723466.130141] ata6.00: device reported invalid CHS sector 0\r\nJul 17 19:20:39 hbase2-rs3 kernel: [9723466.130144] ata6.00: device reported invalid CHS sector 0\r\nJul 17 19:20:39 hbase2-rs3 kernel: [9723466.130147] ata6.00: device reported invalid CHS sector 0\r\nJul 17 19:20:39 hbase2-rs3 kernel: [9723466.130150] ata6.00: device reported invalid CHS sector 0\r\nJul 17 19:20:39 hbase2-rs3 kernel: [9723466.130153] ata6.00: device reported invalid CHS sector 0\r\nJul 17 19:20:39 hbase2-rs3 kernel: [9723466.130156] ata6.00: device reported invalid CHS sector 0\r\nJul 17 19:20:39 hbase2-rs3 kernel: [9723466.130161] ata6.00: device reported invalid CHS sector 0\r\nJul 17 19:20:39 hbase2-rs3 kernel: [9723466.130164] ata6.00: device reported invalid CHS sector 0\r\nJul 17 19:20:39 hbase2-rs3 kernel: [9723466.130167] ata6.00: device reported invalid CHS sector 0\r\nJul 17 19:21:12 hbase2-rs3 kernel: [9723498.978410] ata6.00: device reported invalid CHS sector 0\r\nJul 17 19:21:12 hbase2-rs3 kernel: [9723498.978412] ata6.00: device reported invalid CHS sector 0\r\nJul 17 19:21:12 hbase2-rs3 kernel: [9723498.978413] ata6.00: device reported invalid CHS sector 0\r\nJul 17 19:21:12 hbase2-rs3 kernel: [9723498.978416] ata6.00: device reported invalid CHS sector 0\r\nJul 17 19:21:12 hbase2-rs3 kernel: [9723498.978418] ata6.00: device reported invalid CHS sector 0\r\nJul 17 19:21:12 hbase2-rs3 kernel: [9723498.978445] ata6: EH complete","[Web - CSS/JS] Sliding Toggle Lock":"/* Build the sliding lock toggle as shown here.\r\n\r\nClosed state: https://s3.amazonaws.com/uploads.hipchat.com/10509/34604/z20sjqndkyv6u25/Screen%20Shot%202012-07-27%20at%2012.13.14%20PM.png\r\n\r\nOpen state: https://s3.amazonaws.com/uploads.hipchat.com/10509/34604/5qee35g11hv504a/Screen%20Shot%202012-07-27%20at%2012.12.54%20PM.png\r\n\r\nWhen clicking on the closed state, the button state should change, and then the \"Keep Open\" content should smoothly slide out. Upon clicking again, the checkbox should slide back in.\r\n\r\nPlease markup, style, and use JS as appropriate to implement this.\r\n*/\r\n","Uppercase and Lowercase":"// To execute Java, please define \"static void main\" on a class\r\n// named Solution.\r\n\r\n/*\r\nDocument of M characters from\r\nAlphabet of N characters (set)\r\nO(1) toUpperCase function ('a' -\u003E 'A', 'A' -\u003E 'A', ';' -\u003E ';')\r\n\r\nWrite:\r\n\r\ntoLowerCase\r\n*/\r\n\r\nclass Solution {\r\n  public static void main(String[] args) {\r\n    System.out.println(\"\"));\r\n  }\r\n}\r\n","Peeking Iterator":"// To execute Scala, please define main on an object named Solution\r\n// Unfortunately, Scala interpreted mode is not supported yet\r\n\r\n// Implement a Java/Scala peeking iterator\r\n// A peeking iterator 'peeks' at the next element in an iterator if it exists, without consuming it.\r\n\r\nabstract class PeekingIterator\u003CT\u003E {\r\n  public boolean hasNext();\r\n  public T next();\r\n  public T peek();\r\n}\r\n\r\nobject Solution {\r\n  def main() {\r\n    println(\"\")\r\n  }\r\n}\r\n","3rd Largest Element":"/* Given an list of elements of size N where N \u003E= 3, find the 3rd largest element in O(N) time */\r\n\r\nclass Solution {\r\n  public static void main(String[] args) {\r\n\r\n    System.out.println(\"\"));\r\n  }\r\n}\r\n","DevOps - Storage Survey":"# On a cluster of 500 linux systems, how can we get a quick one-off guess at the total amount of local disk capacity installed? \r\n","Football Scores":"/* In a football game, a team can accumulate points in increments of 1,2,3, and 6. Given a team's final score, write a program to list all the possible ways this score could be obtained using the available increments. Ideally, generalize the program so it can be used for any set of possible point increments. */\r\n\r\nclass Solution {\r\n  public static void main(String[] args) {\r\n\r\n  }\r\n}\r\n","[Web - JS] Closures \u0026 Events":"\u003C-- Given the following markup (assume these are the only buttons on the page), write a function, using raw JS, that throws an alert popup whenever a button is clicked, showing the index of the button \r\n\r\n    \u003Cbutton\u003EFoo\u003C/button\u003E\r\n    \u003Cbutton\u003EBar\u003C/button\u003E\r\n    \u003Cbutton\u003EMoo\u003C/button\u003E\r\n    \u003Cbutton\u003ECow\u003C/button\u003E --\u003E"}
</script>
<script src="https://cdn.firebase.com/v0/firebase.js"></script>


  
  
<div class="modal fade" id="switching-language-modal" tabindex="-1" role="dialog" aria-hidden="true">
  <div class="modal-dialog">
    <div class="modal-content">
      
  <p>The pad's language is switching to: <span></span>&hellip;</p>
  <p>Everyone&rsquo;s tabs will refresh shortly.</p>

    </div>
  </div>
</div>


<div class="modal fade" id="settings-modal" tabindex="-1" role="dialog" aria-hidden="true">
  <div class="modal-dialog">
    <div class="modal-content">
      
  <h3><span class="fui-gear"></span>Pad Settings</h3>
  <ul>
    <li>
      <h4>Language</h4>
      <p>Warning: Changing the pad language will refresh the window for all participants.</p>
      <select class="selectpicker" id="language-select" name="language-select"><option value="c">C</option>
<option value="csharp">C#</option>
<option value="cpp">C++</option>
<option value="clojure">Clojure</option>
<option value="coffeescript">CoffeeScript</option>
<option value="go">Go</option>
<option value="haskell">Haskell</option>
<option selected="selected" value="java">Java</option>
<option value="javascript">JavaScript</option>
<option value="markdown">Markdown</option>
<option value="objc">Objective-C</option>
<option value="php">PHP</option>
<option value="perl">Perl</option>
<option value="python">Python</option>
<option value="ruby">Ruby</option>
<option value="scala">Scala</option></select>
    </li>
    <li>
      <h4>Tab &nbsp;Spacing</h4>
      <p>Control the number of spaces used for indentation.</p>
      <select class="selectpicker" id="tab-type-select" name="tab-type-select"><option selected="selected" value="2">2 Space Tabs</option>
<option value="4">4 Space Tabs</option>
<option value="8">8 Space Tabs</option></select>
    </li>
  </ul>

    </div>
  </div>
</div>


<div class="modal fade" id="create-modal" tabindex="-1" role="dialog" aria-hidden="true">
  <div class="modal-dialog">
    <div class="modal-content">
      
    <div class="modal-body clearfix">
      <h4>Choose the language for your new pad:</h4>

      <form accept-charset="UTF-8" action="/" class="new_pad" id="new_pad" method="post"><div style="margin:0;padding:0;display:inline"><input name="utf8" type="hidden" value="&#x2713;" /></div>
        <div class="clearfix">
            <ul>
              <li class="header">Interpreted</li>
                <li>
                  <input id="pad_language_coffeescript" name="pad[language]" type="radio" value="coffeescript" />
                  <label for="pad_language_coffeescript">CoffeeScript</label>
                </li>
                <li>
                  <input id="pad_language_javascript" name="pad[language]" type="radio" value="javascript" />
                  <label for="pad_language_javascript">JavaScript</label>
                </li>
                <li>
                  <input id="pad_language_perl" name="pad[language]" type="radio" value="perl" />
                  <label for="pad_language_perl">Perl</label>
                </li>
                <li>
                  <input id="pad_language_php" name="pad[language]" type="radio" value="php" />
                  <label for="pad_language_php">PHP</label>
                </li>
                <li>
                  <input id="pad_language_python" name="pad[language]" type="radio" value="python" />
                  <label for="pad_language_python">Python</label>
                </li>
                <li>
                  <input checked="checked" id="pad_language_ruby" name="pad[language]" type="radio" value="ruby" />
                  <label for="pad_language_ruby">Ruby</label>
                </li>
            </ul>
            <ul>
              <li class="header">Compiled</li>
                <li>
                  <input id="pad_language_c" name="pad[language]" type="radio" value="c" />
                  <label for="pad_language_c">C</label>
                </li>
                <li>
                  <input id="pad_language_clojure" name="pad[language]" type="radio" value="clojure" />
                  <label for="pad_language_clojure">Clojure</label>
                </li>
                <li>
                  <input id="pad_language_cpp" name="pad[language]" type="radio" value="cpp" />
                  <label for="pad_language_cpp">C++</label>
                </li>
                <li>
                  <input id="pad_language_csharp" name="pad[language]" type="radio" value="csharp" />
                  <label for="pad_language_csharp">C#</label>
                </li>
                <li>
                  <input id="pad_language_go" name="pad[language]" type="radio" value="go" />
                  <label for="pad_language_go">Go</label>
                </li>
                <li>
                  <input id="pad_language_haskell" name="pad[language]" type="radio" value="haskell" />
                  <label for="pad_language_haskell">Haskell</label>
                </li>
                <li>
                  <input id="pad_language_java" name="pad[language]" type="radio" value="java" />
                  <label for="pad_language_java">Java</label>
                </li>
                <li>
                  <input id="pad_language_objc" name="pad[language]" type="radio" value="objc" />
                  <label for="pad_language_objc">Objective-C</label>
                </li>
                <li>
                  <input id="pad_language_scala" name="pad[language]" type="radio" value="scala" />
                  <label for="pad_language_scala">Scala</label>
                </li>
            </ul>
            <ul>
              <li class="header">Documents</li>
                <li>
                  <input id="pad_language_markdown" name="pad[language]" type="radio" value="markdown" />
                  <label for="pad_language_markdown">Markdown</label>
                </li>
            </ul>
        </div>
        <p>
          <input class="btn btn-primary" name="commit" type="submit" value="Create Pad" /> or
          <input class="btn btn-primary" name="commit" type="submit" value="Launch Google Hangout" />
        </p>
</form>    </div>

    </div>
  </div>
</div>



  <script src="//ajax.googleapis.com/ajax/libs/jquery/2.1.0/jquery.min.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jqueryui/1.10.4/jquery-ui.min.js"></script>
    <script src="//cdn.ravenjs.com/1.1.2/jquery,native/raven.min.js"></script>
    <script>
      Raven.config('https://4d747205c6ed435c889710eaead44e12@app.getsentry.com/10579', {
        includePaths: [
          /localhost/,
          /coderpad\.io/,
          /vincentwoo\.com/,
          /d146h09pbg0b1a\.cloudfront/
        ],
        ignoreUrls: [
          /graph\.facebook\.com/i,
          /connect\.facebook\.net\/en_US\/all\.js/i,
          /eatdifferent\.com\.woopra-ns\.com/i,
          /static\.woopra\.com\/js\/woopra\.js/i,
          /extensions\//i,
          /^chrome:\/\//i,
          /127\.0\.0\.1:4001\/isrunning/i,
          /webappstoolbarba\.texthelp\.com\//i,
          /metrics\.itunes\.apple\.com\.edgesuite\.net\//i
        ]
      }).install();
    </script>
  <script src="//d146h09pbg0b1a.cloudfront.net/assets/application-ac1fc5b18aff7c11b7c357930bb008e9.js"></script>
</body>
</html>
